{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_CPGbE9Mw8M"
      },
      "source": [
        "**Create Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lnLiaJNMlwe"
      },
      "source": [
        "## 9\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "def face_extractor(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
        "    \n",
        "    if faces is ():\n",
        "        return None\n",
        "    \n",
        "    for (x,y,w,h) in faces:\n",
        "        cropped_face = img[x:x+w, y:y+h]\n",
        "    \n",
        "    return cropped_face\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "count=0\n",
        "\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    if face_extractor(frame) is None:\n",
        "        print('Face not Found')\n",
        "        pass\n",
        "    else:\n",
        "        count+=1\n",
        "        face = cv2.resize(face_extractor(frame), (200,200))\n",
        "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        img_save_path = './faces/sagar/' + str(count) + '.jpg'\n",
        "        cv2.imwrite(img_save_path, face)\n",
        "        \n",
        "        cv2.imshow('Capturing Images', face)\n",
        "        \n",
        "        \n",
        "    if cv2.waitKey(1) == 13 or count==100:\n",
        "        break\n",
        "        \n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(\"Collecting Sample Completes\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kM07HMMNGyz"
      },
      "source": [
        "**Whatsapp**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PEqc8JkMsyQ"
      },
      "source": [
        "def WhatsApp():\n",
        "    current_time = datetime.datetime.now()\n",
        "    kt.sendwhatmsg(\"+919079177035\", \"Face Recognition Successfull!\", current_time.hour, current_time.minute+1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywEZNnfVNcEh"
      },
      "source": [
        "**Email**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n7qABHPMs0r"
      },
      "source": [
        "def sendEmail():\n",
        "    fromaddr = \"lapuidea771@gmail.com\"\n",
        "    toaddr = \"sgrgyanchandani@gmail.com\"\n",
        "\n",
        "    # instance of MIMEMultipart\n",
        "    msg = MIMEMultipart()\n",
        "\n",
        "    # storing the senders email address\n",
        "    msg['From'] = fromaddr\n",
        "\n",
        "    # storing the receivers email address\n",
        "    msg['To'] = toaddr\n",
        "\n",
        "    # storing the subject\n",
        "    msg['Subject'] = \"Face REcognition Test\"\n",
        "\n",
        "    # string to store the body of the mail\n",
        "    body = \"Hello, Face Recognition Successfulll\"\n",
        "\n",
        "    # attach the body with the msg instance\n",
        "    msg.attach(MIMEText(body, 'plain'))\n",
        "\n",
        "    # open the file to be sent\n",
        "    filename = \"image.jpg\"\n",
        "    attachment = open(\"image.jpg\", \"rb\")\n",
        "\n",
        "    # instance of MIMEBase and named as p\n",
        "    p = MIMEBase('application', 'octet-stream')\n",
        "\n",
        "    # To change the payload into encoded form\n",
        "    p.set_payload((attachment).read())\n",
        "\n",
        "    # encode into base64\n",
        "    encoders.encode_base64(p)\n",
        "\n",
        "    p.add_header('Content-Disposition', \"attachment; filename= %s\" % filename)\n",
        "\n",
        "    # attach the instance 'p' to instance 'msg'\n",
        "    msg.attach(p)\n",
        "\n",
        "    # creates SMTP session\n",
        "    s = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "\n",
        "    # start TLS for security\n",
        "    s.starttls()\n",
        "\n",
        "    # Authentication\n",
        "    s.login(fromaddr, \"jairam4567\")\n",
        "\n",
        "    # Converts the Multipart msg into a string\n",
        "    text = msg.as_string()\n",
        "\n",
        "    # sending the mail\n",
        "    s.sendmail(fromaddr, toaddr, text)\n",
        "\n",
        "    # terminating the session\n",
        "    s.quit()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9jOZR9oNhm7"
      },
      "source": [
        "**Launch EC2 Instance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGgRnmB6Ms3l"
      },
      "source": [
        "import time\n",
        "def aws_operation():\n",
        "    os.system(\"aws ec2 run-instances --image-id ami-0ad704c126371a549 --instance-type t2.micro --count 1 --subnet-id subnet-a35fb8c8 --security-group-ids sg-0a821d02796fab09b --key-name aws_key_pair\")\n",
        "    os.system(\"aws ec2 create-volume --availability-zone ap-south-1a --size 5\")\n",
        "    print(\"Hello, Your ec2 instance launched and Volumed created\")\n",
        "    print(\"Please Wait for at least 1 min till we attach the volume\")\n",
        "    time.sleep(30)\n",
        "    InstanceId = os.popen('''aws ec2 describe-instances --filters Name=instance-state-name,Values=running  --query \"Reservations[*].Instances[*].{Instance:InstanceId}\" --output text''').read()\n",
        "    VolumeId = os.popen('''aws ec2 describe-volumes --filters Name=status,Values=available Name=size,Values=5 --query \"Volumes[*].VolumeId\" --output text''').read()\n",
        "    print(\"You volume attached to your instance\")\n",
        "    print(\"Thank You\")\n",
        "    os.system(\"aws ec2 attach-volume  --volume-id \" + VolumeId[:-1] + \" --instance-id \" + InstanceId[:-1] + \" --device /dev/sdf\")\n",
        "    \n",
        "aws_operation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNEYci54NzEU"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqX8UYKIMs6H"
      },
      "source": [
        "## 14\n",
        "import cv2\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "\n",
        "\n",
        "training_data = []\n",
        "labels = []\n",
        "\n",
        "#1\n",
        "data_path = './faces/sagar/'\n",
        "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
        "\n",
        "for i, files in enumerate(onlyfiles):\n",
        "    img_path = data_path + onlyfiles[i]\n",
        "    images = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    training_data.append(np.asarray(images, dtype=np.uint8))\n",
        "    labels.append(1)\n",
        "  \n",
        "#2\n",
        "data_path = './faces/rishabh/'\n",
        "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
        "\n",
        "for i, files in enumerate(onlyfiles):\n",
        "    img_path = data_path + onlyfiles[i]\n",
        "    images = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    training_data.append(np.asarray(images, dtype=np.uint8))\n",
        "    labels.append(2)\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "labels = np.asarray(labels, dtype=np.int32)\n",
        "\n",
        "model = cv2.face_LBPHFaceRecognizer.create()\n",
        "\n",
        "model.train(np.asarray(training_data), np.asarray(labels))\n",
        "\n",
        "model.write('model_saved.yml')\n",
        "\n",
        "print(\"Model trained sucessefully\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZTAObs1OAyY"
      },
      "source": [
        "**Run Our Recognition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDQbvmchMs8h"
      },
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import smtplib\n",
        "\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.base import MIMEBase\n",
        "from email import encoders\n",
        "\n",
        "import pywhatkit as kt\n",
        "import datetime \n",
        "\n",
        "import time\n",
        "\n",
        "AWS_Instance=False\n",
        "MailandWhatsapp=False\n",
        "\n",
        "\n",
        "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "model = cv2.face_LBPHFaceRecognizer.create()\n",
        "model.read('model_saved.yml')\n",
        "\n",
        "def face_detector(img, size=0.5):\n",
        "    \n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
        "    if faces is ():\n",
        "        return img, []\n",
        "    \n",
        "    \n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),1)\n",
        "        roi = img[y:y+h, x:x+w]\n",
        "        roi = cv2.resize(roi, (200, 200))\n",
        "    return img, roi\n",
        "\n",
        "\n",
        "# Open Webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    image, face = face_detector(frame)\n",
        "    \n",
        "    try:\n",
        "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Pass face to prediction model\n",
        "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
        "        results = model.predict(face)\n",
        "#         print(results[0])\n",
        "        \n",
        "        if results[1] < 500:\n",
        "            confidence = int( 100 * (1 - (results[1])/400) )\n",
        "            display_string = str(confidence) + '% Confident it is User'\n",
        "            \n",
        "        \n",
        "        \n",
        "        if results[0]==1:\n",
        "            if confidence > 80:\n",
        "                cv2.putText(image, \"Hello, Sagar\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
        "                cv2.putText(image, display_string, (0, 50), cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 1, (255,255,250), 2)\n",
        "                cv2.imshow('Face Recognition', image )\n",
        "                \n",
        "                if AWS_Instance==False:\n",
        "                    cv2.destroyAllWindows()\n",
        "                        \n",
        "                    print(\"Hello Sagar, Your Instance in on the way!!)\n",
        "                    aws_operation()\n",
        "                    AWS_Instance=True\n",
        "                    cv2.imshow('Face Recognition', image )\n",
        "                \n",
        "        elif(results[0]==2):\n",
        "            if confidence > 80:\n",
        "                cv2.putText(image, \"Hello, Rishabh\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
        "                cv2.putText(image, display_string, (0, 50), cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 1, (255,255,250), 2)\n",
        "                cv2.imshow('Face Recognition', image )\n",
        "                \n",
        "                if MailandWhatsApp==False:\n",
        "                    cv2.destroyAllWindows()\n",
        "                    cv2.imwrite(\"image.jpg\", image)\n",
        "                    \n",
        "                    print(\"Intruder Alert\")\n",
        "                    print(\"Sending Email and Opening WhatsApp\")\n",
        "                    sendEmail()\n",
        "                    print(\"Email sent successfull!!!\")\n",
        "                    WhatsApp()\n",
        "                    MailandWhatsApp=True\n",
        "                    cv2.imshow('Face Recognition', image )\n",
        "            \n",
        "\n",
        "         \n",
        "        else: \n",
        "            cv2.putText(image, \"Unknown Person\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "            cv2.imshow('Face Recognition', image )\n",
        "\n",
        "    except:\n",
        "        cv2.putText(image, \"Unknown Person\", (220, 120) , cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "        cv2.putText(image, \"Looking for Face\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "        cv2.imshow('Face Recognition', image )\n",
        "        pass\n",
        "        \n",
        "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
        "        break\n",
        "   \n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNc0myg4Ms_1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}